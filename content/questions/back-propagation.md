---
filename: back-propagation.md
title: Алгоритм обратного распространения ошибки
Summary: >
    Градиентный спуск — самый используемый алгоритм обучения, он применяется почти в каждой модели машинного обучения.

date: 2022-01-10T13:52:03+03:00
билеты: ["Билет 12", ]
draft: false
weight: 18
cover:
  image: https://miro.medium.com/max/1400/1*LB10KFg5J7yK1MLxTXcLdQ.jpeg
author: "Ilya Kochankov"
---

## Перцептрон

Перцептро́н — математическая или компьютерная модель восприятия информации мозгом (кибернетическая модель мозга).

Согласно современной терминологии, перцептроны могут быть классифицированы как искусственные нейронные сети:
- с одним скрытым слоем.
- с пороговой передаточной функцией.
- с прямым распространением сигнала.

{{< figure src="/images/uploads/perseptron.png"
class="figure__image" >}}

На рисунке представлена структура однослойного перцептрона с \\( M \\) входами и \\( K \\) выходами. 

Очевидно, что каждый выход соответствует своему нейрону единственного слоя.

Количество весовых коэффициентов \\( N_w \\), настраиваемых в процессе обучения, рассчитывается следующим образом:

\\( N_w = (M+1) * K \\)

Для каждого нейрона сети помимо синаптических связей с элементами входного вектора настраивается связь 
с фиктивным единичным входом (коэффициент смещения).

Так как выходные переменные могут принимать как бинарные, так и аналоговые значения, 
выбор вида активационных функций ограничен только областью допустимых значений выходных сигналов, принятой для нормализации.

## Обучение Перцептрона

Однослойные перцептроны обучаются на основе итерационного метода Уидроу–Хоффа, 
иначе называемого дельта-правилом. Алгоритм данного метода следующий:

1. Весовые коэффициенты однослойного перцептрона выбранной структуры инициализируются небольшими по абсолютной величине случайными значениями.
2. На входы перцептрона подается входной вектор одного из примеров обучающей выборки. 
Производится прямое распространение сигналов по сети с расчетом значений выходных переменных \\( \widetilde{y}^p_j \\).
3. Для каждого рассчитанного значения выходной переменной вычисляется погрешность по сравнению со 
значениями элементов выходного вектора взятого обучающего примера: \\( \widetilde{y}^n_j \\)

\\( \Delta = \widetilde{y}^p_j  - \widetilde{y}^n_j \\)

4. Выполняется коррекция старых значений весовых коэффициентов каждого нейрона \\( w^q_{ij} \\) на основе погрешности соответствующей 
выходной переменной:

\\(  w^{(q+1)}\_{ij} = w^{(q)}_{ij} + v\Delta_j\widetilde{x}_i \\)

где \\( v \\) – коэффициент скорости обучения.

5. Цикл повторяется с шага 2 до выполнения одного или нескольких условий окончания:
   - исчерпано заданное предельное количество эпох обучения.
   - достигнут удовлетворительный уровень ошибки по всей обучающей выборке.
   - не происходит уменьшения ошибки обучающей выборки на протяжении заданного предельного количества эпох обучения.


> Коэффициент скорости обучения задается положительной константой или переменной величиной \\(0 < v \leq 1 \\), 
> постепенно уменьшающейся в процессе обучения нейронной сети.

## Многослойный перцептрон

{{< figure src="/images/uploads/multilayer-perseptron.png"
class="figure__image" >}}

Многослойные перцептроны эффективны при решении тех же самых задач, что и однослойные перцептроны, но 
обладают значительно большей вычислительной способностью в сравнении с однослойными перцептронами. 

Благодаря этой своей способности они могут гораздо точнее описывать многомерные зависимости с большой 
степенью нелинейности и высоким уровнем перекрестного и группового влияния входных переменных на выходные.

Пример двухслойного перцептрона с \\( M \\) входами и \\( K \\) выходами был ранее приведен на рисунке. 

При необходимости использования сетей более сложной структуры добавляются новые скрытые слои или наращивается
количество нейронов в скрытых слоях.

Для каждого нейрона сети помимо синаптических связей с элементами входного вектора настраивается связь с 
фиктивным единичным входом (коэффициент смещения).

Метод Уидроу–Хоффа, рассмотренный в предыдущем разделе, не может быть использован для настройки весовых 
коэффициентов многослойных перцептронов, поскольку он позволяет сделать прямую коррекцию по величине ошибки 
только для нейронов выходного слоя, тогда как синаптические коэффициенты скрытых нейронов также требуют изменения.

Задача обучения многослойных перцептронов может быть сформулирована как оптимизационная, в которой целевой функцией
(критерием оптимизации) является общая ошибка, рассчитанная по обучающей выборке. 

Соответственно, и решать данную задачу можно как любую задачу многомерной оптимизации с использованием методов 
детерминированного, градиентного или стохастического поиска.

## Обучение многослойного перцептрона
### Градиентный спуск

Градиентный спуск — самый используемый алгоритм обучения, он применяется почти в каждой модели машинного обучения. 

Градиентный спуск — это, по сути, и есть то, как обучаются модели. Без ГС машинное обучение не было бы там, где сейчас. 

Метод градиентного спуска с некоторой модификацией широко используется для обучения персептрона и глубоких нейронных 
сетей, и известен как **метод обратного распространения ошибки**.

Суть алгоритма – процесс получения наименьшего значения ошибки. 

Аналогично это можно рассматривать как спуск во впадину в попытке найти золото на дне ущелья (самое низкое значение ошибки).

{{< figure src="/images/uploads/gradient-alg.png"
class="figure__image" >}}

Благодаря мат анализу мы знаем, что наклон графика функции – производная от функции по переменной. 

Это наклон всегда указывает на ближайшую впадину!

{{< figure src="/images/uploads/one-var-grad.png"
class="figure__image" >}}

На рисунке мы видим график функции потерь с одним весом. 
Теперь, если мы вычислим наклон функции потерь относительно одного веса, то получим направление, в котором нужно 
двигаться, чтобы достичь локальных минимумов. 

Теперь, когда мы определили направление, в котором нужно подтолкнуть вес, нам нужно понять, как это сделать. 

Тут мы используем коэффициент скорости обучения, его называют гипер-параметром. Гипер-параметр – значение, 
требуемое вашей моделью, о котором мы действительно имеем очень смутное представление. 

Обычно эти значения могут быть изучены методом проб и ошибок. 

Это была функция потерь построенная на один вес. 
В реальной модели мы делаем всё перечисленное выше для всех весов, перебирая все примеры обучения.

### Метод обратного распространения ошибки

Рассмотрим процесс обучения нейронной сети с использованием алгоритма обратного распространения ошибки.

Для иллюстрации этого процесса используем нейронную сеть состоящую из трёх слоёв и имеющую два входа и один выход:

{{< figure src="/images/uploads/back_prop/img.png"
class="figure__image" >}}

Каждый нейрон состоит из двух элементов: 
  - Первый элемент – дендриты — добавляют весовые коэффициенты ко входным сигналам.
  - Второй элемент – тело — реализует нелинейную функцию, т.н. функцию активации нейрона.

Сигнал е – это взвешенная сумма входных сигналов

у = f (е) — выходной сигнал нейрона.

{{< figure src="/images/uploads/back_prop/img_1.png"
class="figure__image" >}}

Каждый шаг обучения начинается с воздействия входных сигналов из тренировочных примеров. 

После этого мы можем определить значения выходных сигналов для всех нейронов в каждом слое сети.

Иллюстрации ниже показывают, как сигнал распространяется по сети.

{{< figure src="/images/uploads/back_prop/img_2.png"
class="figure__image" >}}

{{< figure src="/images/uploads/back_prop/img_3.png"
class="figure__image" >}}

{{< figure src="/images/uploads/back_prop/img_4.png"
class="figure__image" >}}

Распространение сигнала через скрытый слой. Символы \\( w_{mn} \\) представляют весовые множители связей между выходом 
нейрона m и входом нейрона n в следующем слое.

{{< figure src="/images/uploads/back_prop/img_5.png"
class="figure__image" >}}

{{< figure src="/images/uploads/back_prop/img_6.png"
class="figure__image" >}}

Распространение сигнала через выходной слой

{{< figure src="/images/uploads/back_prop/img_7.png"
class="figure__image" >}}

На следующем шаге алгоритма, выходной сигнала сети y сравнивается с желаемым выходным сигналом z, 
который хранится в тренировочных данных.

Разница между этими двумя сигналами называется ошибкой d выходного слоя сети.

{{< figure src="/images/uploads/back_prop/img_8.png"
class="figure__image" >}}

Невозможно непосредственно вычислить сигнал ошибки для внутренних нейронов, 
потому что выходные значения этих нейронов, неизвестны.

На протяжении многих лет был неизвестен эффективный метод для обучения многослойной сети. 

Только в середине восьмидесятых годов был разработан алгоритм обратного распространения ошибки.

Идея заключается в распространении сигнала ошибки d (вычисленного в шаге обучения) обратно на все нейроны, 
чьи выходные сигналы были входящими для последнего нейрона.

Фактически, мы просто находим производную сложной функции (функции ошибки). Но сначала, мы находим (распространяем) производную
функции ошибки по выходам слоев, а затем для каждого нейрона считаем производную по весовым коэффициентам.

{{< figure src="/images/uploads/back_prop/img_9.png"
class="figure__image" >}}

{{< figure src="/images/uploads/back_prop/img_10.png"
class="figure__image" >}}

Весовые коэффициенты \\( w_{mn} \\), используемые для обратного распространения ошибки, 
равны тем же коэффициентам, что использовались во время вычисления выходного сигнала. 

Только изменяется направление потока данных (сигналы передаются от выхода ко входу).

> По сути мы находим производную по выходам нейронов

Этот процесс повторяется для всех слоёв сети. Если ошибка пришла от нескольких нейронов — она суммируется:

{{< figure src="/images/uploads/back_prop/img_11.png"
class="figure__image" >}}

{{< figure src="/images/uploads/back_prop/img_12.png"
class="figure__image" >}}

{{< figure src="/images/uploads/back_prop/img_13.png"
class="figure__image" >}}

Когда вычисляется величина ошибки сигнала для каждого нейрона – можно скорректировать весовые коэффициенты каждого 
узла ввода (дендрита) нейрона.

{{< figure src="/images/uploads/back_prop/img_14.png"
class="figure__image" >}}

{{< figure src="/images/uploads/back_prop/img_15.png"
class="figure__image" >}}

{{< figure src="/images/uploads/back_prop/img_16.png"
class="figure__image" >}}

{{< figure src="/images/uploads/back_prop/img_17.png"
class="figure__image" >}}

{{< figure src="/images/uploads/back_prop/img_18.png"
class="figure__image" >}}

{{< figure src="/images/uploads/back_prop/img_19.png"
class="figure__image" >}}

Коэффициент \\( \eta \\) влияет на скорость обучения сети.

Есть несколько методов для выбора этого параметра:

- Первый способ — начать учебный процесс с большим значением параметра \\( \eta \\). Во время коррекции весовых 
коэффициентов, параметр постепенно уменьшают.
- Второй — более сложный метод обучения, начинается с малым значением параметра \\( \eta \\). В процессе обучения 
параметр увеличивается, а затем вновь уменьшается на завершающей стадии обучения.
Начало учебного процесса с низким значением параметра \\( \eta \\) позволяет определить знак весовых коэффициентов.

### Виды градиентных спусков

У градиентных методов есть свои недостатки:
- Застревание в локальных минимумах или седловых точках, коих для функции от 10^6 переменных может быть очень много.
- Сложный ландшафт целевой функции: плато чередуются с регионами сильной нелинейности. Производная на плато практически равна нулю, а внезапный обрыв, наоборот, может отправить нас слишком далеко.
- Некоторые параметры обновляются значительно реже других, особенно когда в данных встречаются информативные, но редкие признаки, что плохо сказывается на нюансах обобщающего правила сети. С другой стороны, придание слишком большой значимости вообще всем редко встречающимся признакам может привести к переобучению.
- Слишком маленькая скорость обучения заставляет алгоритм сходиться очень долго и застревать в локальных минимумах, слишком большая — «пролетать» узкие глобальные минимумы или вовсе расходиться

Вычислительной математике известны продвинутые алгоритмы второго порядка, которым под силу найти хороший минимум 
и на сложном ландшафте, но тут удар снова наносит количество весов.

Чтобы воспользоваться честным методом второго порядка «в лоб», придётся посчитать гессиан - матрицу производных по 
каждой паре параметров пары параметров (уже плохо) - а, скажем, для метода Ньютона, ещё и обратную к ней. 

Приходится изобретать всяческие ухищрения, чтобы справиться с проблемами, оставляя задачу вычислительно подъёмной.

#### Nesterov Accelerated Gradient

Сама по себе идея методов с накоплением импульса до очевидности проста: «Если мы некоторое время движемся в 
определённом направлении, то, вероятно, нам следует туда двигаться некоторое время и в будущем». 

Для этого нужно уметь обращаться к недавней истории изменений каждого параметра. 
Можно хранить последние n экземпляров изменения параметров сети и на каждом шаге по-честному считать среднее, 
но такой подход занимает слишком много памяти для больших n.

#### Adagrad

Некоторые признаки могут быть крайне информативными, но встречаться редко. 
Экзотическая высокооплачиваемая профессия, причудливое слово в спам-базе — они запросто потонут в шуме 
всех остальных обновлений. 

Речь идёт не только о редко встречающихся входных параметрах. Скажем, вам вполне могут встретиться редкие графические 
узоры, которые и в признак-то превращаются только после прохождения через несколько слоёв свёрточной сети. 

Хорошо бы уметь обновлять параметры с оглядкой на то, насколько типичный признак они фиксируют. 
Достичь этого несложно: давайте будем хранить для каждого параметра сети сумму квадратов его обновлений. 

Она будет выступать в качестве прокси для типичности: если параметр принадлежит цепочке часто активирующихся 
нейронов, его постоянно дёргают туда-сюда, а значит сумма быстро накапливается.

#### RMSProp

Недостаток Adagrad в том, что сумма квадратов обновлений может увеличиваться сколько угодно, что через некоторое 
время приводит к слишком маленьким обновлениям и параличу алгоритма.

Модифицируем идею Adagrad: мы всё так же собираемся обновлять меньше веса, которые слишком часто обновляются, 
но вместо полной суммы обновлений, будем использовать усреднённый по истории квадрат градиента.

#### Adam

Adam — adaptive moment estimation, ещё один оптимизационный алгоритм. Он сочетает в себе и идею накопления движения 
и идею более слабого обновления весов для типичных признаков.
